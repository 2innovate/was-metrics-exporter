#!/usr/bin/env python
'''
This script processes an output file as generated by the performance servlet of WebSphere

@author <a href="hhuebler@2innovate.at">Hermann Huebler</a>
'''
#######################
from types import DictType, ListType, IntType
from utils import options as o
from utils import logger as l
import sys
reload(sys)
import os
import os.path
import re
import ssl
##### import xml.dom
##### import xml.dom.minidom
import datetime
import time
import json
import xml.etree.ElementTree as ET
import urllib
import urllib2
import httplib

# Default encoding should be utf-8
sys.setdefaultencoding('utf8')
# emulate Boolean
(False, True) = (0, 1)

@l.logEntryExit
def wcvGetDate(sep=""):
    '''
    Returns the date as YYYYmmdd
    '''
    return str(time.strftime("%Y"+ sep + "%m" + sep +"%d"))


@l.logEntryExit
def wcvGetTime(sep=""):
    '''
    Returns the time as hhmmss
    '''
    return str(time.strftime("%H" + sep + "%M" + sep + "%S"))


@l.logEntryExit
def getNamesDict():
    '''
    Translate the statistics name as provided by the performance servlet to
    a shorter name
    '''
    statNames = {}
    statNames["ARD requests"] = "ard"
    statNames["client"] = "client"
    statNames["DCS Statistics"] = "dcs"
    statNames["Durable Subscriptions"] = "dsubs"
    statNames["Garbage Collection"] = "gc"
    statNames["HAManager"] = "ham"
    statNames["Interceptors"] = "interceptors"
    statNames["JCA Connection Pools"] = "jca"
    statNames["JVM Runtime"] = "jvm"
    statNames["MessageStoreStats"] = "msgstore"
    statNames["Monitor"] = "mon"
    statNames["Object"] = "obj"
    statNames["Object Pool"] = "objp"
    statNames["ORB"] = "orb"
    statNames["Queues"] = "queues"
    statNames["Schedulers"] = "schedulers"
    statNames["server"] = "server"
    statNames["Servlet Session Manager"] = "session"
    statNames["SipContainerModule"] = "sip"
    statNames["StatGroup"] = "statgroup"
    statNames["System Data"] = "system"
    statNames["Thread"] = "thread"
    statNames["Thread_Pool"] = "threadpool"
    statNames["Thread Pools"] = "threadpools"
    statNames["Topicspaces"] = "topic"
    statNames["Transaction Manager"] = "txm"
    statNames["Web Applications"] = "apps"
    statNames["Web services"] = "ws"
    statNames["Web services Gateway"] = "wsg"
    statNames["xdProcessModule"] = "xd"

    return statNames


@l.logEntryExit
def translateStatName(statName):
    '''
    Gets the name for the stat as provided by the servlet and returns the translated
    name as per getNamesDict(). If the name is not in the getNamesDict() we return
    the name untranslated
    '''
    statNamesDict = getNamesDict()
    if (statNamesDict.get(statName) != None):
        return statNamesDict[statName]
    else:
        return statName


@l.logEntryExit
def getMeasurement(tagsString):
    '''
    Returns the measurement name based on the tagsString
    '''
    return tagsString.split(NODE_SEPARATOR)[0]


@l.logEntryExit
def getTagsString(tagsString):
    '''
    Builds the tags String for the influx DB write
    '''
    rtnString = ""
    tagsList = tagsString.split(NODE_SEPARATOR)

    for x in range(len(tagsList)):
        if (x == 0):
            rtnString += ",cell=" + tagsList[x].replace(" ", "_")
        elif(x==1):
            rtnString += ",node=" + tagsList[x].replace(" ", "_")
        elif(x==2):
            rtnString += ",server=" + tagsList[x].replace(" ", "_")
        elif(x==3):
            rtnString += ",j2eetype=" + tagsList[x].replace(" ", "_")
        elif(x==4):
            rtnString += ",module=" + translateStatName(tagsList[x]).replace(" ", "_")
        else:
            labelName = "label" + str(x)
            rtnString += "," + labelName + "=" + tagsList[x].replace(" ", "_")

    l.debug("influx DB tags string: '%s'" % (rtnString))
    return rtnString


@l.logEntryExit
def getFieldString(perfDataDict):
    '''
    Returns the string with the fields and values to be added to the influx DB
    '''
    rtnString = ""
    perfName = perfDataDict["name"].replace(" ", "_")
    if (perfDataDict["classificaton"] == "CountStatistic"):
        rtnString += perfName + ".count" + "=" + perfDataDict["count"]
    elif (perfDataDict["classificaton"] == "AverageStatistic"):
        rtnString += perfName + ".count" + "=" + perfDataDict["count"]
        rtnString += "," + perfName + ".max" + "=" + perfDataDict["max"]
        rtnString += "," + perfName + ".mean" + "=" + perfDataDict["mean"]
        rtnString += "," + perfName + ".min" + "=" + perfDataDict["min"]
        rtnString += "," + perfName + ".total" + "=" + perfDataDict["total"]
        rtnString += "," + perfName + ".sumOfSquares" + "=" + perfDataDict["sumOfSquares"]
    elif (perfDataDict["classificaton"] == "TimeStatistic"):
        rtnString += perfName + ".max" + "=" + perfDataDict["max"]
        rtnString += "," + perfName + ".totalTime" + "=" + perfDataDict["totalTime"]
        rtnString += "," + perfName + ".min" + "=" + perfDataDict["min"]
    elif (perfDataDict["classificaton"] == "RangeStatistic"):
        rtnString += perfName + ".highWaterMark" + "=" + perfDataDict["highWaterMark"]
        rtnString += "," + perfName + ".integral" + "=" + perfDataDict["integral"]
        rtnString += "," + perfName + ".lowWaterMark" + "=" + perfDataDict["lowWaterMark"]
        rtnString += "," + perfName + ".mean" + "=" + perfDataDict["mean"]
        rtnString += "," + perfName + ".value" + "=" + perfDataDict["value"]
    elif (perfDataDict["classificaton"] == "BoundedRangeStatistic"):
        rtnString += perfName + ".highWaterMark" + "=" + perfDataDict["highWaterMark"]
        rtnString += "," + perfName + ".integral" + "=" + perfDataDict["integral"]
        rtnString += "," + perfName + ".lowWaterMark" + "=" + perfDataDict["lowWaterMark"]
        rtnString += "," + perfName + ".lowerBound" + "=" + perfDataDict["lowerBound"]
        rtnString += "," + perfName + ".mean" + "=" + perfDataDict["mean"]
        rtnString += "," + perfName + ".upperBound" + "=" + perfDataDict["upperBound"]
        rtnString += "," + perfName + ".value" + "=" + perfDataDict["value"]
    else:
        l.error("Invalid classificaton in perfDataDict found: '%s'. Exiting ..." % (perfDataDict["classificaton"]))
        sys.exit(1)

    l.debug("Returning field string: \n'%s'\n for performance data dictionary:\n'%s'" % (rtnString, str(perfDataDict)))
    return rtnString


@l.logEntryExit
def getFieldsString(perfDataDictList):
    '''
    Returns the string with the fields and values to be added to the influx DB
    '''
    rtnString = ""
    for dataDict in perfDataDictList:
        rtnString += ',' + getFieldString(dataDict)

    ##
    ## If we have a leading "," we remove it
    if (rtnString.startswith(",")):
        rtnString = rtnString[1:]

    l.debug("Returning fields string: \n'%s'" % (rtnString))
    return rtnString


@l.logEntryExit
def buildQueryString(**kwargs):
    '''
    Returns the encoded query string for the keyword list
    '''
    debugString = ""
    rtnString = ""
    rtnDict = {}
    ##
    ## Build a debug string
    for key, value in kwargs.items():
        debugString += "'%s'='%s';" % (str(key), str(value))
    l.debug("debugString: '%s'" % (debugString))
    ##
    ## Build the query String
    for key, value in kwargs.items():
        ##
        ## Only if there is a value
        if ((value != None) and (value != "")):
            rtnDict[key] = value

    l.debug("Query string unencoded: '%s'" % (str(rtnDict)))
    rtnString = urllib.urlencode(rtnDict)
    if (rtnString != ""):
        rtnString = "?" + rtnString
    l.debug("Query string encoded: '%s'" % (rtnString))
    ##
    ## Return the encoded string
    return rtnString


@l.logEntryExit
def splitHttpUrlString(urlString):
    '''
    Takes an URL String like for example http://localhost:8086 and returns a tuple of (schema, host, port)
    '''
    l.debug("Splitting URL String: '%s'" % (urlString))
    urlList = urlString.split(":")
    urlSchema = urlList[0]
    ##
    ## Only http and https URLs are supported
    if (not urlSchema in ("http", "https")):
        l.error("The URL schema '%s' is not supported" % (urlSchema))
        raise Exception, 'Unsupported URL schema found'
    ##
    ## Hostname is the second list entry after the ":"
    urlHost = urlList[1].replace("/", "")
    ##
    ## Get the port or set the defauls port if none is provided
    if (len(urlList) > 2):
        urlPort = urlList[2].replace("/", "")
    else:
        if (urlSchema == HTTP_SCHEMA):
            urlPort = '80'
        elif(urlSchema == HTTPS_SCHEMA):
            urlPort = '443'
        else:
            pass
    l.debug("urlSchema: '%s'; urlHost: '%s'; urlPort: '%s'" % (urlSchema, urlHost, urlPort))

    return (urlSchema, urlHost, urlPort)


@l.logEntryExit
def getHttpConnection(urlSchema, urlHost, urlPort):
    '''
    returns the HTTP connection object
    '''
    l.debug("urlSchema: '%s'; urlHost: '%s'; urlPort: '%s'" % (urlSchema, urlHost, urlPort))
    if (urlSchema == HTTP_SCHEMA):
        conn = httplib.HTTPConnection(urlHost, port=urlPort, timeout=3, strict=1)
    else:
        conn = httplib.HTTPSConnection(urlHost, port=urlPort, timeout=3, strict=1)
    ##
    ## Connection successfull?
    ##
    ## Return the connection object
    return conn


@l.logEntryExit
def getUrlSchema(perfServletUrl):
    '''
    Returns the schema of an Url
    '''
    return re.sub(r"^(.*?):.*", r"\1", perfServletUrl)


@l.logEntryExit
def getHostFromUrl(perfServletUrl):
    '''
    Returns the host of an Url
    '''
    return re.sub(r"^.*?\/\/(.*?)[:\/].*", r"\1", perfServletUrl)


@l.logEntryExit
def getPortFromUrl(perfServletUrl):
    '''
    Returns the port of an Url
    '''
    port = re.sub(r"^.*?\/\/.*?:([0-9]*?)\/.*", r"\1", perfServletUrl)
    if (port == perfServletUrl):
        return None
    else:
        return port


@l.logEntryExit
def getPerfServletData(perfServletUrl, wasUser=None, wasPassword=None):
    '''
    Read the performance servlet data
    '''
    rtnString = ""
    l.debug("Getting performace servlet data from URL: '%s' using user: '%s' / '%s'" % (perfServletUrl, wasUser, wasPassword))
    ##
    ## Create a password manager for basic authentication
    if ((wasUser != None) and (wasUser != "")):
        passwordMgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
        urlSchema = getUrlSchema(perfServletUrl)
        urlHost = getHostFromUrl(perfServletUrl)
        urlPort = getPortFromUrl(perfServletUrl)
        if (urlPort == None):
            topLevelUrl = urlSchema + "://" + urlHost + "/"
        else:
            topLevelUrl = urlSchema + "://" + urlHost + ":" + urlPort + "/"
        passwordMgr.add_password(None, topLevelUrl, wasUser, wasPassword)
        passwordHandler = urllib2.HTTPBasicAuthHandler(passwordMgr)
        urlOpener = urllib2.build_opener(passwordHandler)
        urllib2.install_opener(urlOpener)

    ##### urlEncoded = urllib.urlencode(perfServletUrl)
    ##### l.debug("Encoded URL: '%s'" % (urlEncoded))
    try:
        requestXml = urllib2.Request(perfServletUrl)
        response = urllib2.urlopen(requestXml)
    except urllib2.HTTPError as e2:
        errorString = "Fetching performance servlet data failed with code: '%s' and return text: \n'%s'" % (e2.code, e2.read())
        l.error(errorString)
        rtnString = None
    except urllib2.URLError as e1:
        errorString = "Fetching performance servlet data failed with: '%s'" % (e1.reason)
        l.error(errorString)
        rtnString = None
    else:
        rtnString = response.read()
        l.debug("Performance servlet call returned '%d' bytes" % (len(rtnString)))

    return rtnString


@l.logEntryExit
def buildDictFromXmlNode(statistics_node):
    '''
    Converts the statistics_node to a dictionary with the attributes in List attrList
    '''
    l.logEntryExit("Entering: statistics_node.tag: '%s'; statistics_node.name: '%s'" % (statistics_node.tag, statistics_node.get("name")))
    rtnDict = {}

    nodeAttrDict = statistics_node.attrib
    ##### l.debug("Dictionary of node attributes: '%s'", (str(nodeAttrDict)))

    rtnDict["classificaton"] = statistics_node.tag
    for attr in nodeAttrDict.keys():
        rtnDict[attr] = statistics_node.get(attr)
    ##
    ## return the built dictionary
    l.debug("buildDictFromXmlNode returns '%s'", (str(rtnDict)))
    return rtnDict


@l.logEntryExit
def processLeafNode(xmlNode, parentNodeNames):
    '''
    Processes a leaf node of the XML structure and returns a dictionary with the performance data
    '''
    l.logEntryExit("Entering: parentNodeNames: '%s'; xmlNode: '%s', xmlNode.taf: '%s'" % (str(parentNodeNames), xmlNode.get("name"), xmlNode.tag))

    statsDataDict = {}
    statisticDataDictList = []
    ##
    ## Check all available statistics
    for statClassification in STATISTIC_CLASSIFICATION_LIST:
        l.debug("Checking for statistic classification: '%s'" % (statClassification))
        xPathString = "./" + statClassification
        for statistics_node in xmlNode.findall(xPathString):
            l.debug("Processing node: '%s'" % (statistics_node.get("name", "N/A")))
            statisticDataDict = {}
            ##
            ##  Depending on the node tag we have to build out dictionary
            if statistics_node.tag in STATISTIC_CLASSIFICATION_LIST:
                statisticDataDict = buildDictFromXmlNode(statistics_node)
            else:
                l.error("Invalid tag of XML node found: '%s'. Exiting ..." % (statistics_node.tag))
                sys.exit(1)
            ##
            ## Append statistic data to returned list
            statisticDataDictList.append(statisticDataDict)
    ##
    ## Create a dictionary to include the tags and the data
    statsDataDict["tags"] = parentNodeNames
    statsDataDict["perfdata"] = statisticDataDictList
    ##### jsonStats = json.dumps(statsDataDict)
    ##### l.debug("Return list for node '%s' as JSON: '%s'" % (xmlNode.get("name"), str(jsonStats)))
    l.debug("Returned dictionary for node '%s': '%s'" % (xmlNode.get("name"), str(statsDataDict)))

    return statsDataDict


@l.logEntryExit
def getStatsData(parentNodeNames, xmlNode):
    '''
    Returns the recursive stats records from the current node.
    Note: The result is a List of Dictionaries
    '''
    l.logEntryExit("Entering: parentNodeNames: '%s'; xmlNode: '%s'" % (str(parentNodeNames), xmlNode.get("name")))

    parentNodeNames += NODE_SEPARATOR
    parentNodeNames += xmlNode.get("name")
    l.debug("Added to parentNodeNames: '%s'. New parentNodeNames is:\n '%s'" % (xmlNode.get("name"), str(parentNodeNames)))
    ##
    ## Do we have sub statistcs
    subStatNode = xmlNode.find("./Stat")
    if (subStatNode != None):
        subStatNodeList = []
        ##
        ## process all sub Stat nodes
        for subStatNode in xmlNode.findall("./Stat"):
            subStatNodeName = subStatNode.get("name")
            l.debug("processing subStatNode: '%s'" % (subStatNodeName))
            getStatsDataResult = getStatsData(parentNodeNames, subStatNode)
            l.debug("Returning from recursion; getStatsDataResult is: '%s'" % (str(json.dumps(getStatsDataResult))))

            if (isinstance(getStatsDataResult, DictType)):
                subStatNodeList.append(getStatsDataResult)
            elif (isinstance(getStatsDataResult, ListType)):
                subStatNodeList += getStatsDataResult
            else:
                l.error("Type of returned getStatsDataResult is invalid. Exiting ...")
                ## l.error("Got '%s' back" % (str(getStatsDataResult)))
                sys.exit(1)
        ##
        ## Some PMI data objects contain accumulated values as well (like for example JDBC Provider)
        subNodeStatsDict = processLeafNode(xmlNode, parentNodeNames)
        l.debug("Statistics Dictionary for Stat node: '%s'" % (str(subNodeStatsDict)))
        ##
        ## We add dictionary only to the returned list if there are data
        if (len(subNodeStatsDict["perfdata"]) > 0):
            l.debug("appending subNodeStatsDict: '%s'" % (str(json.dumps(subNodeStatsDict))))
            subStatNodeList.append(subNodeStatsDict)

        return subStatNodeList

    else:
        ##
        ## No sub Stat nodes --> a leaf found.
        l.debug("Leaf node: '%s' found" % (xmlNode.get("name")))
        subStatNodeList = []
        leafNodeResult = processLeafNode(xmlNode, parentNodeNames)
        ##
        ## We return a list!
        subStatNodeList.append(leafNodeResult)
        return subStatNodeList


@l.logEntryExit
def getNodes(wasCellName, root):
    '''
    Returns a list of performance records
    '''
    l.logEntryExit("Entering: root: '%s'; wasCellName: '%s'" % (str(root), wasCellName))

    nodeName = None
    serverName = None
    statName = None
    parentNodeNames = ""
    statRtnList = []
    ##
    ## Check for a valid file via the root node tag (PerformanceMonitor)
    l.debug("XML tag of the root node is: '%s'" % (root.tag))
    if (root.tag == "PerformanceMonitor"):
        responseStatus = root.get('responseStatus')
        if (responseStatus != 'success'):
            l.error("PerformanceMonitor responseStatus indicates an invalid file!")
        else:
            l.verbose("PerformanceMonitor responseStatus indicates a valid file!")
    ##
    ## process sub-nodes
    for nodeNode in root.findall("./Node"):
        l.verbose("Processing xmlNode.tag: '%s'" % (nodeNode.tag))
        parentNodeNames += wasCellName
        ##
        ## Node nodes
        if (nodeNode.tag == "Node"):
            nodeName = nodeNode.get('name')
            parentNodeNames += NODE_SEPARATOR
            parentNodeNames += nodeName
            l.debug("nodeName set to: '%s'" % (nodeName))
            ##
            ## Server nodes
            for serverNode in nodeNode.findall("./Server"):
                if (serverNode.tag == "Server"):
                    serverName = serverNode.get('name')
                    parentNodeNames += NODE_SEPARATOR
                    parentNodeNames += serverName
                    l.debug("serverName set to: '%s'" % (serverName))
                    ##
                    ## Get all Stats nodes of the server node
                    for statNode in serverNode.findall("./Stat"):
                        if (statNode.tag == "Stat"):
                            statName = statNode.get('name')
                            l.debug("Found child node with name: '%s'" % (statNode.get("name")))

                            debugList = getStatsData(parentNodeNames, statNode)
                            statRtnList += debugList
                            l.debug("JSON-0 debugList: '%s'" % (str(json.dumps(debugList))))
                            l.debug("JSON-1 statRtnList: '%s'" % (str(json.dumps(statRtnList))))
        else:
            l.debug("Expected nodeNode.tag to be \"Node\" but got: '%s'" % (nodeNode.tag))

    return statRtnList


@l.logEntryExit
def removeSummaryData(perfList):
    '''
    Removes the summary entries of the performance data like for example the performance data for the JDBC Provider level
    '''
    oldLenght = len(perfList)
    l.debug("Lenght of performance data list before removal: '%d'" % (oldLenght))
    tmpList = []
    rmvTagsList = []
    for tmpDict in perfList:
        tmpList.append(tmpDict["tags"])

    tmpListLength = len(tmpList)
    l.debug("Lenght of tags list before removal: '%d'" % (tmpListLength))

    tmpList.sort()
    for i in range(tmpListLength - 1):
        if (tmpList[i + 1].startswith(tmpList[i])):
            rmvTagsList.append(tmpList[i])
            l.debug("Removing tag entry: '%s'" % (tmpList[i]))
    ##
    ## Build the return list
    perfList = [x for x in perfList if (x["tags"] not in rmvTagsList)]
    newLenght = len(perfList)
    l.debug("Lenght of performance data list after removal: '%d'" % (newLenght))

    return (perfList)


@l.logEntryExit
def writeToInflux(parmInfluxUrl, parmInfluxDb, parmTargetUser, parmTargetPwd, perfList):
    '''
    writes the data to the influx DB using the write REST API
    '''
    l.debug("writeToInflux with the following parameters: \nparmInfluxUrl: '%s'\n parmInfluxDb: '%s'\n parmTargetUser: '%s'\n parmTargetPwd: '%s'\n len(perfList): : '%s'" % (parmInfluxUrl, parmInfluxDb, parmTargetUser, parmTargetPwd, len(perfList)))
    try:
        (urlSchema, urlHost, urlPort) = splitHttpUrlString(parmInfluxUrl)
    except Exception as e:
        raise Exception, sys.exc_info()[1]
    ##
    ## All the values are reported by the current time in ms
    unixTime = str(time.time()).replace(".", "") + "0"
    ##
    ## influxdb write end-point with query string
    tmpUri = "/write"
    tmpUri += buildQueryString(db=parmInfluxDb, precision="ms", p=parmTargetPwd, u=parmTargetUser)
    l.debug("Uri to /write Influx: '%s'" % (tmpUri))

    postHeaders = {"Content-type": "text/plain; charset=utf-8", "Accept": "text/plain"}
    ##
    ## Number of rows inserted
    rowCount = 0
    ##
    ## iterate over the perflist and build the REST API string.
    ## The "tags" is string of tags separated by NODE_SEPARATOR and the counters will be the fields
    for perfListEntry in perfList:
        ##
        ## Get the tags string
        xmlTagString = perfListEntry["tags"]
        perfDataDictList = perfListEntry["perfdata"]
        ##
        ## get the measure from the tags
        measurement = getMeasurement(xmlTagString)
        tagsString = getTagsString(xmlTagString)
        fieldsString = getFieldsString(perfDataDictList)
        postData = measurement + tagsString + " " + fieldsString + " " + unixTime
        l.debug("POST data for write end-point: '%s'" % (postData))
        ##
        ##
        try:
            ##
            ## Get the HTTP Connection
            httpConn = getHttpConnection(urlSchema, urlHost, urlPort)
            httpConn.request("POST", tmpUri, postData, postHeaders)
            httpResponse = httpConn.getresponse()
            responseData = httpResponse.read()
            httpConn.close()
            rowCount += 1
        except Exception as e2:
            httpConn.close()
            errorString = "Failed to write data to influx, '%s'" % (e2.strerror)
            raise Exception, errorString
        ##
        ## indluxDb write returns code 204
        if (httpResponse.status != httplib.NO_CONTENT):
            l.error("Error response data: '%s'" % (responseData))
            errorString = "Write to influx db failed with status code: '%d'", httpResponse.status
            l.error(errorString)
            httpConn.close()
            raise Exception, errorString
        else:
            l.debug("influx URL ping returned status code: '%d'", httpResponse.status)
    ##
    ## Finished - close the connection
    httpConn.close()
    l.info("writeToInflux: Number of rows inserted: '%d'" % (rowCount))


@l.logEntryExit
def outputFormatter(perfList, outFormat=None):
    '''
    formats data as specified by outFormat and returns a String
    '''
    ##
    ## All the values are reported by the current time in ms
    unixTime = str(time.time()).replace(".", "") + "0"
    ##
    ## influxdb write end-point with query string

    ##
    ## Number of rows inserted
    rowCount = 0
    postDataList = []
    ##
    ## iterate over the perflist and build the REST API string.
    ## The "tags" is string of tags separated by NODE_SEPARATOR and the counters will be the fields
    for perfListEntry in perfList:
        ##
        ## Get the tags string
        xmlTagString = perfListEntry["tags"]
        perfDataDictList = perfListEntry["perfdata"]
        # l.info(perfListEntry)
        ##
        ## get the measure from the tags
        measurement = getMeasurement(xmlTagString)
        tagsString = getTagsString(xmlTagString)
        fieldsString = getFieldsString(perfDataDictList)
        tagList = tagsString.split(",")
        fieldList = fieldsString.split(",")
        if l.isDebugEnabled():
            l.debug("Tag list:")
            for f in tagList:
                l.debug("-  %s", f)
            l.debug("field list:")
            for f in fieldList:
                l.debug("-  %s", f)

        fieldsString = " ".join(fieldList)
        tagsString = " ".join(tagList)
        postData = "{}-{} {} {}".format(wcvGetDate(), wcvGetTime(), tagsString, fieldsString)
        print postData
        postDataList.append(postData)

    l.verbose("Number of rows returned: '%d'" % (len(postDataList)))
    return "\n".join(postDataList)


'''
Main ... the start of the execution :)
'''
@l.logEntryExit
def main():
    ##
    ## General prologue
    ##
    l.info("%s" % (SEPARATOR_LINE))
    l.info("Script: %s/%s" % (WCV_SCRIPT_PATH, WCV_SCRIPTNAME))
    l.info("Date = %s / Time = %s" % (wcvGetDate("/"), wcvGetTime(":")))
    l.info("%s" % (SEPARATOR_LINE))
    
    ##
    ## parse CLI command line arguments
    l.debug("sys.argv=%s" % (sys.argv))
    sysArgv = sys.argv[1:]
    ## Copy the parameter values to the variables
    (parmServletXmlFile, parmPerfServletUrl, parmJsonOutFileName, parmWasCellName, parmNoEmpty, parmReplace, parmOmitSummary, parmInfluxUrl,
     parmInfluxDb, parmSeconds, parmTargetUser, parmTargetPwd, parmWasUser, parmWasPwd, parmOutFileName, parmOutFormat) = o.parseArguments(WCV_SCRIPTNAME, sysArgv)

    curDate = str(datetime.datetime.now().date())
    curTime = datetime.datetime.now().strftime("%H:%M:%S")
    ##
    ## If we start AFTER the endTime, we run until the next day's stopTime!! otherwise we end today ...
    endDate = datetime.datetime.now()
    if (curTime >= TERMINATE_AT):
        endDate = endDate + datetime.timedelta(days=1)

    endDate = str(endDate.date())
    l.debug("curDate: '%s', curTime: '%s', endDate: '%s'" % (curDate, curTime, endDate))
    while ((endDate > curDate) or ((endDate == curDate) and (curTime < TERMINATE_AT))):
        ##
        ## if we get an xml file we can parse directly
        if (parmServletXmlFile != None):
            tree1 = ET.parse(parmServletXmlFile)
            root1 = tree1.getroot()
            l.debug("Processing XMl data from file: '%s'" % (parmServletXmlFile))
        else:
            ##
            ## Get the xml from the performance servlet URL
            pmiXmlDataString = getPerfServletData(parmPerfServletUrl, parmWasUser, parmWasPwd)
            if (pmiXmlDataString != None):
                root1 = ET.fromstring(pmiXmlDataString)
                l.debug("Processing XMl data from URL: '%s'" % (parmPerfServletUrl))
            else:
                root1 = None
                l.debug("No PMI data received from: '%s'" % (parmPerfServletUrl))
        ##
        ## Only if we got an XML root node
        if (root1 != None):
            perfList = getNodes(parmWasCellName, root1)
            ##
            ## Should we remove empty "perfdata" lists in the dictionaries
            if (parmNoEmpty == True):
                emptyList = [x for x in perfList if len(x["perfdata"]) == 0]
                numEmptyEntries = len(emptyList)
                l.debug("Number of entries in the emptyList: '%d'" % numEmptyEntries)

                oldLenght = len(perfList)
                perfList = [x for x in perfList if len(x["perfdata"]) != 0]
                newLenght = len(perfList)
                l.debug("Removed empty entries. Old # of entries: '%d'; new # of entries: '%d'" % (oldLenght, newLenght))
            if (parmOmitSummary == True):
                perfList = removeSummaryData(perfList)
            ##
            ## Write data to the outfile if selected
            l.debug("FINALLY: '%s'" % (str(json.dumps(perfList))))
            
            if (parmJsonOutFileName != None):
                outFile = open(parmJsonOutFileName, "w")
                outFile.write(str(json.dumps(perfList)))
                ##
                ## Close outfile
                outFile.close()
            ##
            ## If we have an influx Db to write to ...
            if ((parmInfluxUrl != None) and (parmInfluxUrl != "")):
                writeToInflux(parmInfluxUrl, parmInfluxDb, parmTargetUser, parmTargetPwd, perfList)
                l.info("Data pushed to influx DB")

            ##
            ## append to log file in Splunk-like format "TS key1=value1 key2=value2 ..."
            if (parmOutFileName != None):
                    outFile = open(parmOutFileName, "w")
                    outFile.write(outputFormatter(perfList, parmOutFormat))
                    outFile.close()
                    
        ##
        ## If input was a file we break the loop otherwise we sleep
        if (parmServletXmlFile != None):
            break
        else:
            if ((parmSeconds != None) and (parmSeconds != 0)):
                l.debug("sleeping '%d' seconds" % (parmSeconds))
                time.sleep(parmSeconds)
            else:
                l.info("No valid sleep time (--seconds|-s)provided --> exiting")
                break


###################################### E N D  OF M A I N ##########################################
##
## Some globals ...
##
if (os.environ.get("TWOI_LOG_LEVEL") == None):
    ##
    ## Default log level
    l.setLoglevel(l.LogLevels.INFO)
else:
    l.info("Environment variable 'TWOI_LOG_LEVEL' found. Setting Loglevel to: '%s'" % os.environ.get("TWOI_LOG_LEVEL"))
    l.setLoglevelByName(os.environ.get("TWOI_LOG_LEVEL").upper())
l.debug("Created default logger ...")
##
## Disable SSL Certificate verification
if (not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None)):
    ssl._create_default_https_context = ssl._create_unverified_context

SEPARATOR_LINE = "=" * 120
NODE_SEPARATOR = "|"
HTTP_SCHEMA = "http"
HTTPS_SCHEMA = "https"
STATISTIC_CLASSIFICATION_LIST = ["CountStatistic", "AverageStatistic", "TimeStatistic", "RangeStatistic", "BoundedRangeStatistic"]
TERMINATE_AT = "23:59:59"
WCV_SCRIPTNAME = os.path.basename(__file__)
WCV_SCRIPT_PATH = os.path.dirname(os.path.realpath(__file__))

if __name__ == "__main__":
    rc = main()
    sys.exit(rc)
