#!/usr/bin/env python
'''
This script processes an output file as generated by the performance servlet of WebSphere

@author <a href="hhuebler@2innovate.at">Hermann Huebler</a>
'''
#######################
from types import DictType, ListType, IntType
from lib import options as o
from lib import logger as l
from lib import outputFormatter as fmt
from lib import configReader as cr
import sys
reload(sys)
import os
import os.path
import re
import ssl
##### import xml.dom
##### import xml.dom.minidom
import datetime
import time
import json
import xml.etree.ElementTree as ET
import urllib
import urllib2
import httplib

# Default encoding should be utf-8
sys.setdefaultencoding('utf8')
# emulate Boolean
(False, True) = (0, 1)

@l.logEntryExit
def wcvGetDate(sep=""):
    '''
    Returns the date as YYYYmmdd
    '''
    return str(time.strftime("%Y"+ sep + "%m" + sep +"%d"))


@l.logEntryExit
def wcvGetTime(sep=""):
    '''
    Returns the time as hhmmss
    '''
    return str(time.strftime("%H" + sep + "%M" + sep + "%S"))


@l.logEntryExit
def getPerfServletData(perfServletUrl, wasUser=None, wasPassword=None):
    '''
    Read the performance servlet data
    '''
    rtnString = ""
    l.debug("Getting performace servlet data from URL: '%s' using user: '%s' / '%s'" % (perfServletUrl, wasUser, wasPassword))
    ##
    ## Create a password manager for basic authentication
    if ((wasUser != None) and (wasUser != "")):
        passwordMgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
        urlSchema = o.getUrlSchema(perfServletUrl)
        urlHost = o.getHostFromUrl(perfServletUrl)
        urlPort = o.getPortFromUrl(perfServletUrl)
        if (urlPort == None):
            topLevelUrl = urlSchema + "://" + urlHost + "/"
        else:
            topLevelUrl = urlSchema + "://" + urlHost + ":" + urlPort + "/"
        passwordMgr.add_password(None, topLevelUrl, wasUser, wasPassword)
        passwordHandler = urllib2.HTTPBasicAuthHandler(passwordMgr)
        urlOpener = urllib2.build_opener(passwordHandler)
        urllib2.install_opener(urlOpener)

    ##### urlEncoded = urllib.urlencode(perfServletUrl)
    ##### l.debug("Encoded URL: '%s'" % (urlEncoded))
    try:
        requestXml = urllib2.Request(perfServletUrl)
        response = urllib2.urlopen(requestXml)
    except urllib2.HTTPError as e2:
        errorString = "Fetching performance servlet data failed with code: '%s' and return text: \n'%s'" % (e2.code, e2.read())
        l.error(errorString)
        rtnString = None
    except urllib2.URLError as e1:
        errorString = "Fetching performance servlet data failed with: '%s'" % (e1.reason)
        l.error(errorString)
        rtnString = None
    else:
        rtnString = response.read()
        l.debug("Performance servlet call returned '%d' bytes" % (len(rtnString)))

    return rtnString


@l.logEntryExit
def buildDictFromXmlNode(statistics_node):
    '''
    Converts the statistics_node to a dictionary with the attributes in List attrList
    '''
    l.logEntryExit("Entering: statistics_node.tag: '%s'; statistics_node.name: '%s'" % (statistics_node.tag, statistics_node.get("name")))
    rtnDict = {}

    nodeAttrDict = statistics_node.attrib
    ##### l.debug("Dictionary of node attributes: '%s'", (str(nodeAttrDict)))

    rtnDict["classificaton"] = statistics_node.tag
    for attr in nodeAttrDict.keys():
        rtnDict[attr] = statistics_node.get(attr)
    ##
    ## return the built dictionary
    l.debug("buildDictFromXmlNode returns '%s'", (str(rtnDict)))
    return rtnDict


@l.logEntryExit
def processLeafNode(xmlNode, parentNodeNames):
    '''
    Processes a leaf node of the XML structure and returns a dictionary with the performance data
    '''
    l.logEntryExit("Entering: parentNodeNames: '%s'; xmlNode: '%s', xmlNode.taf: '%s'" % (str(parentNodeNames), xmlNode.get("name"), xmlNode.tag))

    statsDataDict = {}
    statisticDataDictList = []
    ##
    ## Check all available statistics
    for statClassification in STATISTIC_CLASSIFICATION_LIST:
        l.debug("Checking for statistic classification: '%s'" % (statClassification))
        xPathString = "./" + statClassification
        for statistics_node in xmlNode.findall(xPathString):
            l.debug("Processing node: '%s'" % (statistics_node.get("name", "N/A")))
            statisticDataDict = {}
            ##
            ##  Depending on the node tag we have to build out dictionary
            if statistics_node.tag in STATISTIC_CLASSIFICATION_LIST:
                statisticDataDict = buildDictFromXmlNode(statistics_node)
            else:
                l.error("Invalid tag of XML node found: '%s'. Exiting ..." % (statistics_node.tag))
                sys.exit(1)
            ##
            ## Append statistic data to returned list
            statisticDataDictList.append(statisticDataDict)
    ##
    ## Create a dictionary to include the tags and the data
    statsDataDict["tags"] = parentNodeNames
    statsDataDict["perfdata"] = statisticDataDictList
    ##### jsonStats = json.dumps(statsDataDict)
    ##### l.debug("Return list for node '%s' as JSON: '%s'" % (xmlNode.get("name"), str(jsonStats)))
    l.debug("Returned dictionary for node '%s': '%s'" % (xmlNode.get("name"), str(statsDataDict)))

    return statsDataDict


@l.logEntryExit
def getStatsData(parentNodeNames, xmlNode):
    '''
    Returns the recursive stats records from the current node.
    Note: The result is a List of Dictionaries
    '''
    l.logEntryExit("Entering: parentNodeNames: '%s'; xmlNode: '%s'" % (str(parentNodeNames), xmlNode.get("name")))

    parentNodeNames += NODE_SEPARATOR
    parentNodeNames += xmlNode.get("name")
    l.debug("Added to parentNodeNames: '%s'. New parentNodeNames is:\n '%s'" % (xmlNode.get("name"), str(parentNodeNames)))
    ##
    ## Do we have sub statistcs
    subStatNode = xmlNode.find("./Stat")
    if (subStatNode != None):
        subStatNodeList = []
        ##
        ## process all sub Stat nodes
        for subStatNode in xmlNode.findall("./Stat"):
            subStatNodeName = subStatNode.get("name")
            l.debug("processing subStatNode: '%s'" % (subStatNodeName))
            getStatsDataResult = getStatsData(parentNodeNames, subStatNode)
            l.debug("Returning from recursion; getStatsDataResult is: '%s'" % (str(json.dumps(getStatsDataResult))))

            if (isinstance(getStatsDataResult, DictType)):
                subStatNodeList.append(getStatsDataResult)
            elif (isinstance(getStatsDataResult, ListType)):
                subStatNodeList += getStatsDataResult
            else:
                l.error("Type of returned getStatsDataResult is invalid. Exiting ...")
                ## l.error("Got '%s' back" % (str(getStatsDataResult)))
                sys.exit(1)
        ##
        ## Some PMI data objects contain accumulated values as well (like for example JDBC Provider)
        subNodeStatsDict = processLeafNode(xmlNode, parentNodeNames)
        l.debug("Statistics Dictionary for Stat node: '%s'" % (str(subNodeStatsDict)))
        ##
        ## We add dictionary only to the returned list if there are data
        if (len(subNodeStatsDict["perfdata"]) > 0):
            l.debug("appending subNodeStatsDict: '%s'" % (str(json.dumps(subNodeStatsDict))))
            subStatNodeList.append(subNodeStatsDict)

        return subStatNodeList

    else:
        ##
        ## No sub Stat nodes --> a leaf found.
        l.debug("Leaf node: '%s' found" % (xmlNode.get("name")))
        subStatNodeList = []
        leafNodeResult = processLeafNode(xmlNode, parentNodeNames)
        ##
        ## We return a list!
        subStatNodeList.append(leafNodeResult)
        return subStatNodeList


@l.logEntryExit
def getNodes(wasCellName, root):
    '''
    Returns a list of performance records
    '''
    l.logEntryExit("Entering: root: '%s'; wasCellName: '%s'" % (str(root), wasCellName))

    nodeName = None
    serverName = None
    statName = None
    parentNodeNames = ""
    statRtnList = []
    ##
    ## Check for a valid file via the root node tag (PerformanceMonitor)
    l.debug("XML tag of the root node is: '%s'" % (root.tag))
    if (root.tag == "PerformanceMonitor"):
        responseStatus = root.get('responseStatus')
        if (responseStatus != 'success'):
            l.error("PerformanceMonitor responseStatus indicates an invalid file!")
        else:
            l.verbose("PerformanceMonitor responseStatus indicates a valid file!")
    ##
    ## process sub-nodes
    for nodeNode in root.findall("./Node"):
        l.verbose("Processing xmlNode.tag: '%s'" % (nodeNode.tag))
        parentNodeNames += wasCellName
        ##
        ## Node nodes
        if (nodeNode.tag == "Node"):
            nodeName = nodeNode.get('name')
            parentNodeNames += NODE_SEPARATOR
            parentNodeNames += nodeName
            l.debug("nodeName set to: '%s'" % (nodeName))
            ##
            ## Server nodes
            for serverNode in nodeNode.findall("./Server"):
                if (serverNode.tag == "Server"):
                    serverName = serverNode.get('name')
                    parentNodeNames += NODE_SEPARATOR
                    parentNodeNames += serverName
                    l.debug("serverName set to: '%s'" % (serverName))
                    ##
                    ## Get all Stats nodes of the server node
                    for statNode in serverNode.findall("./Stat"):
                        if (statNode.tag == "Stat"):
                            statName = statNode.get('name')
                            l.debug("Found child node with name: '%s'" % (statNode.get("name")))

                            debugList = getStatsData(parentNodeNames, statNode)
                            statRtnList += debugList
                            l.debug("JSON-0 debugList: '%s'" % (str(json.dumps(debugList))))
                            l.debug("JSON-1 statRtnList: '%s'" % (str(json.dumps(statRtnList))))
        else:
            l.debug("Expected nodeNode.tag to be \"Node\" but got: '%s'" % (nodeNode.tag))

    return statRtnList


@l.logEntryExit
def removeSummaryData(perfList):
    '''
    Removes the summary entries of the performance data like for example the performance data for the JDBC Provider level
    '''
    oldLenght = len(perfList)
    l.debug("Lenght of performance data list before removal: '%d'" % (oldLenght))
    tmpList = []
    rmvTagsList = []
    for tmpDict in perfList:
        tmpList.append(tmpDict["tags"])

    tmpListLength = len(tmpList)
    l.debug("Lenght of tags list before removal: '%d'" % (tmpListLength))

    tmpList.sort()
    for i in range(tmpListLength - 1):
        if (tmpList[i + 1].startswith(tmpList[i])):
            rmvTagsList.append(tmpList[i])
            l.debug("Removing tag entry: '%s'" % (tmpList[i]))
    ##
    ## Build the return list
    perfList = [x for x in perfList if (x["tags"] not in rmvTagsList)]
    newLenght = len(perfList)
    l.debug("Lenght of performance data list after removal: '%d'" % (newLenght))

    return (perfList)


@l.logEntryExit
def writeToInflux(parmInfluxUrl, parmInfluxDb, parmTargetUser, parmTargetPwd, perfList, whitelistDict):
    '''
    writes the data to the influx DB using the write REST API
    '''
    l.debug("writeToInflux with the following parameters: \nparmInfluxUrl: '%s'\n parmInfluxDb: '%s'\n parmTargetUser: '%s'\n parmTargetPwd: '%s'\n len(perfList): : '%s'" % (parmInfluxUrl, parmInfluxDb, parmTargetUser, parmTargetPwd, len(perfList)))
    try:
        (urlSchema, urlHost, urlPort) = o.splitHttpUrlString(parmInfluxUrl)
    except Exception as e:
        raise Exception, sys.exc_info()[1]
    ##
    ## influxdb write end-point with query string
    tmpUri = "/write"
    tmpUri += o.buildQueryString(db=parmInfluxDb, precision="ms", p=parmTargetPwd, u=parmTargetUser)
    l.debug("Uri to /write Influx: '%s'" % (tmpUri))

    postHeaders = {"Content-type": "text/plain; charset=utf-8", "Accept": "text/plain"}
    ##
    ## Number of rows inserted
    rowCount = 0
    ##
    ## Format the output as a string
    data = outputFormatter(perfList, outFormat="INFLUX", whitelistDict=whitelistDict)
    l.verbose("formatted influx data: \n%s", data)
    ##
    ## outputFormatter returns a string of the data separated by \n per line
    postDataDict = data.split("\n")
    ##
    ## iterate over the perflist and build the REST API string.
    ## The "tags" is string of tags separated by NODE_SEPARATOR and the counters will be the fields
    for postData in postDataDict:
        l.debug("POST data for write end-point: '%s'" % (postData))
        ##
        ##
        try:
            ##
            ## Get the HTTP Connection
            httpConn = o.getHttpConnection(urlSchema, urlHost, urlPort)
            httpConn.request("POST", tmpUri, postData, postHeaders)
            httpResponse = httpConn.getresponse()
            responseData = httpResponse.read()
            httpConn.close()
            rowCount += 1
        except Exception as e2:
            httpConn.close()
            errorString = "Failed to write data to influx, '%s'" % (e2.strerror)
            raise Exception, errorString
        ##
        ## indluxDb write returns code 204
        if (httpResponse.status != httplib.NO_CONTENT):
            l.error("Error response data: '%s'" % (responseData))
            errorString = "Write to influx db failed with status code: '%d'", httpResponse.status
            l.error(errorString)
            httpConn.close()
            raise Exception, errorString
        else:
            l.debug("influx URL ping returned status code: '%d'", httpResponse.status)
    ##
    ## Finished - close the connection
    httpConn.close()
    l.info("writeToInflux: Number of rows inserted: '%d'" % (rowCount))


@l.logEntryExit
def outputFormatter(perfList, **kwargs):
    '''
    formats data as specified by outFormat passed in via **kwargs and returns a String. Supported keywords are:
    outFormat
    whitelistDict
    '''
    outFormat = None
    whitelistDict = None
    debugString=""

    for key, value in kwargs.items():
        debugString += "'%s'='%s';" % (str(key), str(value))
        if (key == "outFormat"):
            outFormat = value
        elif(key == "whitelistDict"):
            whitelistDict = value
        else:
            l.error("Unsupported key '%s' with value '%s' passed. Exiting ..." % (key, value))
            sys.exit(1)

    l.debug("outputFormatter kwargs: '%s'" % (debugString))

    if outFormat.upper() == "DUMMY":
        formatFunction = fmt.DummyFormatter()

    elif outFormat.upper() == "SPLUNK":
        formatFunction = fmt.SplunkFormatter()

    elif outFormat.upper() == "INFLUX":
        formatFunction = fmt.InfluxFormatter()

    else:
        l.fatal("unknown output formatter: %s", outFormat)

    timeStamp = time.localtime()
    return formatFunction(perfList, timeStamp, whitelistDict)


'''
Main ... the start of the execution :)
'''
@l.logEntryExit
def main():
    ##
    ## General prologue
    ##
    l.info("%s" % (SEPARATOR_LINE))
    l.info("Script: %s/%s" % (WCV_SCRIPT_PATH, WCV_SCRIPTNAME))
    l.info("Date = %s / Time = %s" % (wcvGetDate("/"), wcvGetTime(":")))
    l.info("%s" % (SEPARATOR_LINE))

    ##
    ## parse CLI command line arguments
    l.debug("sys.argv=%s" % (sys.argv))
    sysArgv = sys.argv[1:]
    ## Copy the parameter values to the variables
    (parmServletXmlFile, parmPerfServletUrl, parmJsonOutFileName, parmWasCellName, parmNoEmpty, parmReplace, parmOmitSummary, parmInfluxUrl,
     parmInfluxDb, parmSeconds, parmTargetUser, parmTargetPwd, parmWasUser, parmWasPwd, parmOutFileName, parmOutFormat, parmOutConfigFile) = o.parseArguments(WCV_SCRIPTNAME, sysArgv)
    ##
    ## Get the output configuration file if provided
    whitelistDict = {}
    if parmOutConfigFile:
        whitelistDict = cr.readConfig(parmOutConfigFile)
        whitelistDict = whitelistDict["WHITELIST"]

    curDate = str(datetime.datetime.now().date())
    curTime = datetime.datetime.now().strftime("%H:%M:%S")
    ##
    ## If we start AFTER the endTime, we run until the next day's stopTime!! otherwise we end today ...
    endDate = datetime.datetime.now()
    if (curTime >= TERMINATE_AT):
        endDate = endDate + datetime.timedelta(days=1)

    endDate = str(endDate.date())
    l.debug("curDate: '%s', curTime: '%s', endDate: '%s'" % (curDate, curTime, endDate))
    while ((endDate > curDate) or ((endDate == curDate) and (curTime < TERMINATE_AT))):
        ##
        ## if we get an xml file we can parse directly
        if (parmServletXmlFile != None):
            tree1 = ET.parse(parmServletXmlFile)
            root1 = tree1.getroot()
            l.debug("Processing XMl data from file: '%s'" % (parmServletXmlFile))
        else:
            ##
            ## Get the xml from the performance servlet URL
            pmiXmlDataString = getPerfServletData(parmPerfServletUrl, parmWasUser, parmWasPwd)
            if (pmiXmlDataString != None):
                root1 = ET.fromstring(pmiXmlDataString)
                l.debug("Processing XMl data from URL: '%s'" % (parmPerfServletUrl))
            else:
                root1 = None
                l.debug("No PMI data received from: '%s'" % (parmPerfServletUrl))
        ##
        ## Only if we got an XML root node
        if (root1 != None):
            perfList = getNodes(parmWasCellName, root1)
            ##
            ## Should we remove empty "perfdata" lists in the dictionaries
            if (parmNoEmpty == True):
                emptyList = [x for x in perfList if len(x["perfdata"]) == 0]
                numEmptyEntries = len(emptyList)
                l.debug("Number of entries in the emptyList: '%d'" % numEmptyEntries)

                oldLenght = len(perfList)
                perfList = [x for x in perfList if len(x["perfdata"]) != 0]
                newLenght = len(perfList)
                l.debug("Removed empty entries. Old # of entries: '%d'; new # of entries: '%d'" % (oldLenght, newLenght))
            if (parmOmitSummary == True):
                perfList = removeSummaryData(perfList)
            ##
            ## Write data to the outfile if selected
            l.debug("FINALLY: '%s'" % (str(json.dumps(perfList))))

            if (parmJsonOutFileName != None):
                outFile = open(parmJsonOutFileName, "w")
                outFile.write(str(json.dumps(perfList)))
                ##
                ## Close outfile
                outFile.close()
            ##
            ## If we have an influx Db to write to ...
            if ((parmInfluxUrl != None) and (parmInfluxUrl != "")):
                writeToInflux(parmInfluxUrl, parmInfluxDb, parmTargetUser, parmTargetPwd, perfList, whitelistDict)
                l.info("Data pushed to influx DB")

            ##
            ## append to log file in Splunk-like format "TS key1=value1 key2=value2 ..."
            if (parmOutFileName != None):
                outFile = open(parmOutFileName, "w")
                data = outputFormatter(perfList, outFormat=parmOutFormat, whitelistDict=whitelistDict)
                l.verbose("formatted data: \n%s", data)
                outFile.write(data)
                outFile.close()

        ##
        ## If input was a file we break the loop otherwise we sleep
        if (parmServletXmlFile != None):
            break
        else:
            if ((parmSeconds != None) and (parmSeconds != 0)):
                l.debug("sleeping '%d' seconds" % (parmSeconds))
                time.sleep(parmSeconds)
            else:
                l.info("No valid sleep time (--seconds|-s)provided --> exiting")
                break
        ##
        ## Get the current date / time for the check if we've reached the stoptime .. i.e. time to exit
        curDate=str(datetime.datetime.now().date())
        curTime=datetime.datetime.now().strftime("%H:%M:%S")
        l.debug("curDate: '%s', curTime: '%s', endDate: '%s'" % (curDate, curTime, endDate))

###################################### E N D  OF M A I N ##########################################
##
## Some globals ...
##
if (os.environ.get("TWOI_LOG_LEVEL") == None):
    ##
    ## Default log level
    l.setLoglevel(l.LogLevels.INFO)
else:
    l.info("Environment variable 'TWOI_LOG_LEVEL' found. Setting Loglevel to: '%s'" % os.environ.get("TWOI_LOG_LEVEL"))
    l.setLoglevelByName(os.environ.get("TWOI_LOG_LEVEL").upper())
l.debug("Created default logger ...")
##
## Disable SSL Certificate verification
if (not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None)):
    ssl._create_default_https_context = ssl._create_unverified_context

SEPARATOR_LINE = "=" * 120
NODE_SEPARATOR = "|"
STATISTIC_CLASSIFICATION_LIST = ["CountStatistic", "AverageStatistic", "TimeStatistic", "RangeStatistic", "BoundedRangeStatistic"]
TERMINATE_AT = "23:59:59"
WCV_SCRIPTNAME = os.path.basename(__file__)
WCV_SCRIPT_PATH = os.path.dirname(os.path.realpath(__file__))

if __name__ == "__main__":
    rc = main()
    sys.exit(rc)
